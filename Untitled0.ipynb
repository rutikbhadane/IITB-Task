{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVicKKcIl1u2"
      },
      "outputs": [],
      "source": [
        "# running trial 2\n",
        "import whisper\n",
        "import os\n",
        "\n",
        "# Load the Whisper model (choose a Hindi model if available)\n",
        "model = whisper.load_model(\"medium\")  # Replace with Hindi model if applicable\n",
        "\n",
        "def get_audio_paths(base_path):\n",
        "  \"\"\"\n",
        "  Recursively collects audio file paths within a directory.\n",
        "\n",
        "  Args:\n",
        "      base_path: The base path of the dataset hierarchy.\n",
        "\n",
        "  Returns:\n",
        "      A list of absolute paths to all audio files.\n",
        "  \"\"\"\n",
        "  audio_paths = []\n",
        "  for root, _, files in os.walk(base_path):\n",
        "    for filename in files:\n",
        "      if filename.endswith(\".wav\") or filename.endswith(\".flac\") or filename.endswith(\".mp3\"):\n",
        "        audio_paths.append(os.path.join(root, filename))  # Construct full path\n",
        "  return audio_paths\n",
        "\n",
        "# Example usage\n",
        "base_path = \"/content/drive/MyDrive/kathbath/hindi\"  # Replace with your base path\n",
        "audio_files = get_audio_paths(base_path)\n",
        "\n",
        "def transcribe_hindi_audio(audio_files):\n",
        "  \"\"\"\n",
        "  Transcribes multiple Hindi audio files using Whisper.\n",
        "\n",
        "  Args:\n",
        "      audio_files: A list of absolute paths to audio files.\n",
        "\n",
        "  Returns:\n",
        "      A list of transcription texts (one for each audio file).\n",
        "  \"\"\"\n",
        "  transcriptions = []\n",
        "  for audio_file in audio_files:\n",
        "    try:\n",
        "      result = model.transcribe(audio_file, language=\"hi\")\n",
        "      transcriptions.append(result[\"text\"])\n",
        "    except Exception as e:  # Catch potential errors\n",
        "      print(f\"Error transcribing {audio_file}: {e}\")\n",
        "  return transcriptions\n",
        "\n",
        "# Example usage\n",
        "transcriptions = transcribe_hindi_audio(audio_files)\n",
        "for i, text in enumerate(transcriptions):\n",
        "  print(f\"Transcription for audio file {i+1}: {text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating WER using asr_evaluation\n",
        "#in this code we are yet to upload the ttest file\n",
        "\n",
        "import whisper\n",
        "#from asr_evaluation import word_errors\n",
        "import asr_evaluation\n",
        "\n",
        "import os\n",
        "# Load the Whisper model (choose a Hindi model if available)\n",
        "model = whisper.load_model(\"small\")  # Replace with Hindi model if applicable\n",
        "\n",
        "def get_audio_paths(base_path):\n",
        "  \"\"\"\n",
        "  Recursively collects audio file paths within a directory.\n",
        "\n",
        "  Args:\n",
        "      base_path: The base path of the dataset hierarchy.\n",
        "\n",
        "  Returns:\n",
        "      A list of absolute paths to all audio files.\n",
        "  \"\"\"\n",
        "  audio_paths = []\n",
        "  for root, _, files in os.walk(base_path):\n",
        "    for filename in files:\n",
        "      if filename.endswith(\".wav\") or filename.endswith(\".flac\") or filename.endswith(\".mp3\"):\n",
        "        audio_paths.append(os.path.join(root, filename))  # Construct full path\n",
        "  return audio_paths\n",
        "\n",
        "def transcribe_audio_files(audio_files, model):\n",
        "  \"\"\"\n",
        "  Transcribes audio files using Whisper and returns hypotheses.\n",
        "\n",
        "  Args:\n",
        "      audio_files: A list of paths to audio files.\n",
        "      model: The loaded Whisper model.\n",
        "\n",
        "  Returns:\n",
        "      A list of transcribed text hypotheses (one for each audio file).\n",
        "  \"\"\"\n",
        "  hypotheses = []\n",
        "  for audio_file in audio_files:\n",
        "    result = model.transcribe(audio_file, language=\"hi\")\n",
        "    hypotheses.append(result[\"text\"])\n",
        "  return hypotheses\n",
        "\n",
        "\n",
        "def load_reference_texts(path):\n",
        "    loc = []\n",
        "    for root, _, files in os.walk(path):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".txt\") :\n",
        "                loc.append(os.path.join(root, filename))  # Construct full path\n",
        "    return loc\n",
        "\n",
        "\n",
        "\n",
        "def calculate_wer(references, hypotheses):\n",
        "  \"\"\"\n",
        "  Calculates WER for a list of references and hypotheses.\n",
        "\n",
        "  Args:\n",
        "      references: A list of reference transcript texts.\n",
        "      hypotheses: A list of corresponding hypotheses texts.\n",
        "\n",
        "  Returns:\n",
        "      The average WER across all references and hypotheses.\n",
        "  \"\"\"\n",
        "  total_wer = 0\n",
        "  for reference, hypothesis in zip(references, hypotheses):\n",
        "    total_wer += wer(reference, hypothesis)\n",
        "  return total_wer/reference\n",
        "\n",
        "# Example usage\n",
        "reference_texts = load_reference_texts(\"/content/drive/MyDrive/GV_Eval_3h/text\")  # Replace with your function to load references\n",
        "new_audio_files = get_audio_paths(\"/content/drive/MyDrive/GV_Eval_3h\")  # Replace with your function to get audio paths\n",
        "hypotheses = transcribe_audio_files(new_audio_files, model)\n",
        "wer = calculate_wer(reference_texts, hypotheses)\n",
        "print(\"Word Error Rate (WER):\", wer)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y9pLx62AwMSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bXiM4-oJ9ASF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}